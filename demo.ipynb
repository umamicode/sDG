{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f575f57-77ba-41fc-b358-3b8c1b457305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/simclr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, USPS, SVHN, CIFAR10, STL10\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from tools.autoaugment import SVHNPolicy, CIFAR10Policy\n",
    "from tools.randaugment import RandAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7003b425-81b8-4419-b336-6f87ba949dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27304e8f-6841-49ba-9d6c-43b4962abfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(split='train', translate=None, twox=False, ntr=None, autoaug=None, channels=3):\n",
    "    '''\n",
    "        autoaug == 'AA', AutoAugment\n",
    "                   'FastAA', Fast AutoAugment\n",
    "                   'RA', RandAugment\n",
    "        channels == 3 return by default rgb 3 channel image\n",
    "                    1 Return a single channel image\n",
    "    '''\n",
    "    path = f'data/cifar10-{split}.pkl'\n",
    "    cifar10_transforms_train= transforms.Compose([transforms.Resize((32,32))]) #224,224\n",
    "    if not os.path.exists(path):\n",
    "        dataset = CIFAR10(f'{HOME}/.pytorch/CIFAR10', train=(split=='train'), download=True, transform= cifar10_transforms_train)\n",
    "        x, y = dataset.data, dataset.targets\n",
    "        \n",
    "        #Only Select First 10k images as train\n",
    "        #if split=='train':\n",
    "        #    x, y = x[0:10000], y[0:10000]\n",
    "        \n",
    "        #[TODO] - solve -> AttributeError: 'numpy.ndarray' object has no attribute 'numpy'\n",
    "        #x = torch.tensor(resize_imgs(x.numpy(), 32))\n",
    "        #x = torch.tensor(resize_imgs_dkcho(x, 32)) # x-> torch.Size([10000, 32, 32, 3])\n",
    "        x= torch.tensor(x)\n",
    "        x = (x.float()/255.)#.unsqueeze(1).repeat(1,3,1,1)  #<class 'torch.Tensor'>\n",
    "        x= x.permute(0,3,1,2) #[batchsize,w,h,channel] -> [batchsize, channel, w,h]\n",
    "        y = torch.tensor(y)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    \n",
    "    if ntr is not None:\n",
    "        x, y = x[0:ntr], y[0:ntr]\n",
    "    \n",
    "    # Without Data Augmentation\n",
    "    if (translate is None) and (autoaug is None):\n",
    "        dataset = TensorDataset(x, y)\n",
    "        return dataset\n",
    "    \n",
    "    # Data Augmentation Pipeline\n",
    "    transform = [transforms.ToPILImage()]\n",
    "    if translate is not None:\n",
    "        transform.append(transforms.RandomAffine(0, [translate, translate]))\n",
    "    if autoaug is not None:\n",
    "        if autoaug == 'AA':\n",
    "            transform.append(CIFAR10Policy()) #originally SVHNPolicy()\n",
    "        elif autoaug == 'RA':\n",
    "            transform.append(RandAugment(3,4))\n",
    "    transform.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(transform)\n",
    "    dataset = myTensorDataset(x, y, transform=transform, twox=twox)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_usps(split='train', channels=3):\n",
    "    path = f'data/usps-{split}.pkl'\n",
    "    if not os.path.exists(path):\n",
    "        dataset = USPS(f'{HOME}/.pytorch/USPS', train=(split=='train'), download=True)\n",
    "        x, y = dataset.data, dataset.targets\n",
    "        x = torch.tensor(resize_imgs(x, 32))\n",
    "        x = (x.float()/255.).unsqueeze(1).repeat(1,3,1,1)\n",
    "        y = torch.tensor(y)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3954e302-89df-4e40-921b-5fe68ea821f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn(split='train', channels=3):\n",
    "    dataset = SVHN(f'{HOME}/.pytorch/SVHN', split=split, download=True)\n",
    "    x, y = dataset.data, dataset.labels\n",
    "    x = x.astype('float32')/255.\n",
    "    x, y = torch.tensor(x), torch.tensor(y)\n",
    "    if channels == 1:\n",
    "        x = x.mean(1, keepdim=True)\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df071344-67f6-4f61-878e-1576b540193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pacs(split='train', translate=None, twox=False, ntr=None, autoaug=None, channels=3):\n",
    "    #PACS Dataset\n",
    "    NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "    DATASETS_NAMES = ['photo', 'art', 'cartoon', 'sketch']\n",
    "    CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "    DIR_PHOTO = './data/PACS/photo'\n",
    "    DIR_ART = './data/PACS/art_painting'\n",
    "    DIR_CARTOON = './data/PACS/cartoon'\n",
    "    DIR_SKETCH = './data/PACS/sketch'\n",
    "\n",
    "    path = f'data/pacs-{split}.pkl'\n",
    "\n",
    "    pacs_convertor= {'train':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "    \n",
    "    pacs_transforms_train= transforms.Compose([transforms.ToTensor(),transforms.Resize((224,224))]) #224,224\n",
    "    if not os.path.exists(path):\n",
    "        dataset= torchvision.datasets.ImageFolder(pacs_convertor[split], transform=pacs_transforms_train)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset,batch_size=len(dataset),drop_last=True)\n",
    "        x, y= next(iter(train_loader))\n",
    "        #x, y = dataset.image, dataset.label\n",
    "        x= torch.tensor(x)\n",
    "        #x = (x.float()/255.)#.unsqueeze(1).repeat(1,3,1,1)  #<class 'torch.Tensor'>\n",
    "        #x= x.permute(0,3,1,2) #[batchsize,w,h,channel] -> [batchsize, channel, w,h]\n",
    "        y = torch.tensor(y)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    \n",
    "    if ntr is not None:\n",
    "        x, y = x[0:ntr], y[0:ntr]\n",
    "    \n",
    "    # Without Data Augmentation\n",
    "    if (translate is None) and (autoaug is None):\n",
    "        dataset = TensorDataset(x, y)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca7229f-4839-45d8-b898-9fee73fd74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_m(split='train', channels=3):\n",
    "    path = f'data/mnist_m-{split}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        x, y = torch.tensor(x.astype('float32')/255.), torch.tensor(y)\n",
    "        if channels==1:\n",
    "            x = x.mean(1, keepdim=True)\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8333cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= load_cifar10('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc92590",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size=1,drop_last=True, shuffle=True)\n",
    "x, y= next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e95626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abb33e-8dea-4af1-aa0b-4043c0e427b0",
   "metadata": {},
   "source": [
    "# MNIST-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9deb271-bc73-4f1e-969f-67c7be1115b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= load_mnist_m('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000a9a8-fc43-4c0f-93a0-eefca4a9d8c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30c91c-9be7-4dec-8ea0-7136ded29172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/dongkyu/.pytorch/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dataset= load_svhn('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6aca5d-5918-430c-bdb1-8ab75bb4834e",
   "metadata": {},
   "source": [
    "# PACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39e5f70f-c11c-4996-bedf-9fff590bc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= load_pacs(split='photo')\n",
    "train_size= len(dataset)\n",
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size=train_size,drop_last=True, shuffle=True)\n",
    "\n",
    "x, y= next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba17711-ca20-4477-8ba4-1fe1cedebc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0fcf0631-6693-4e85-b00e-07312dec845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 816, 0: 772, 2: 753, 1: 740, 3: 608, 6: 160, 5: 80})\n"
     ]
    }
   ],
   "source": [
    "y= y.tolist()\n",
    "from collections import Counter\n",
    "c=Counter(y)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "07c6af8b-a70e-489d-b0e9-1baad6f0875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,samplelabel= x[0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a53fd427-3b15-49f3-bc88-8e811af2ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplelabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10450e38-7c6e-479a-b591-7bcc3daec19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topil= transforms.ToPILImage()\n",
    "image= topil(sample)\n",
    "image.save('./data/image_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6020f57-e6ae-4618-9d91-e313a70fd5b2",
   "metadata": {},
   "source": [
    "# Check STL10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e6491ccf-2aea-4b95-8616-c361298bc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stl10(split='train', channels=3):\n",
    "    STL10_transforms_train= transforms.Compose([transforms.Resize((32,32))])\n",
    "    dataset = STL10(f'{HOME}/.pytorch/STL10', split=split, download=True, transform= STL10_transforms_train)\n",
    "    x, y = dataset.data, dataset.labels\n",
    "    x = x.astype('float32')/255.\n",
    "    x, y = torch.tensor(x), torch.tensor(y)\n",
    "    if channels == 1:\n",
    "        x = x.mean(1, keepdim=True)\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "27a9ee61-5f7d-4472-9f60-af46870cf9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset= load_stl10('train')\n",
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size=1,drop_last=True)\n",
    "x, y= next(iter(train_loader))\n",
    "x= x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6b080218-0407-4c42-ba97-d4bda38e3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "topil= transforms.ToPILImage()\n",
    "image= topil(x)\n",
    "image.save('image_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74665b-27b1-48e4-a5a4-11d1658c60db",
   "metadata": {},
   "source": [
    "# Check CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4f3f1622-6459-459e-a8a4-17b59f675eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= load_cifar10('train')\n",
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size=2,drop_last=True)\n",
    "x, y= next(iter(train_loader))\n",
    "x= x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "784ae918-e16e-423f-a111-34536cf13878",
   "metadata": {},
   "outputs": [],
   "source": [
    "topil= transforms.ToPILImage()\n",
    "image= topil(x)\n",
    "image.save('./data/image_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757dd7d-6fff-45c0-ba17-a1fab4cab585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "simclr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
